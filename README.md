# Задание с собеседования ИИ-агент

# Описание

Код использует дообученную модель для классификации высказываний. Он загружает модель, предобрабатывает тексты и выводит категории.

rubert.py - Дообучение модели Rubert
final.py - Запуск модели для проверки классификации
streamlit.py - Запуск UI интерфейса в Streamlit

## Краткие шаги

Код использует модель ruBERT (cointegrated/rubert-tiny2) для классификации высказываний. Он загружает токенизатор и модель, выполняет предсказания и присваивает категории на основе порога вероятности. 

Я дообучил модель. Для дообучения модели ruBERT на задачу классификации высказываний необходимо использовать подходящие русскоязычные датасеты.
Я использовал RuSentiment: Датасет, содержащий русскоязычные тексты с разметкой настроения (положительная, отрицательная, нейтральная). Полезен для задач анализа настроения и классификации текстов.

После получения подходящего датасета приступил к дообучению модели RuBERT, используя библиотеки, такие как Transformers от Hugging Face. Это позволило адаптировать модель к специфике задачи настроения и улучшить качество анализа настроения.

# Пайплайн

Вот пайплайн для дообучения LLM модели, включая подготовку данных, обучение и сохранение модели:
Этап 1: Подготовка данных
    1. Сбор данных – найти или создать размеченный датасет. 
    2. Предобработка – очистка текста, токенизация, разметка категорий. 
    3. Форматирование – преобразование в Dataset (Hugging Face), разделение на train/val/test. 
Этап 2: Загрузка модели
    1. Выбор предобученной LLM (например, cointegrated/rubert-tiny2). 
    2. Настройка количества классов (если классификация). 
    3. Загрузка токенизатора и модели. 
Этап 3: Обучение модели
    1. Определение параметров обучения (batch size, learning rate, epochs). 
    2. Дообучение модели на данных RuSentiment (Dataset (Hugging Face))
Этап 4: Сохранение и тестирование
    1. Сохранение модели и токенизатора. 
    2. Оценка на тестовых данных.
Этап 5: Проверка модели

# Выводы:
К сожалению у меня нет ключа к API openai, поэтому Предложил альтернативное решение без использования обученной LLM модели,  целесообразно и бесплатно